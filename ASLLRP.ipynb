{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c474b-d509-4e87-97a7-260a1c920572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold, cross_val_score, cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "%load_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a62536-9993-4937-81ed-0968d7192f90",
   "metadata": {},
   "source": [
    "## Preprocess Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa2a72-e4c3-4d09-865d-298fd53d4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(frame):\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = tf.image.resize(frame, (224,224))\n",
    "    #frame = frame / 255.0  # Normalize pixel values\n",
    "    return frame\n",
    "    \n",
    "def preprocess_video(video_path, signer):\n",
    "    frames = []\n",
    "    if os.path.exists(video_path):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        label = video_path.split(\"/\")[5]\n",
    "        folder_path = f\".../Test/{label}\"\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        t = 0\n",
    "        while True:\n",
    "            ret, cur_frame = cap.read()\n",
    "            name = video_path.split(\"_\")[9]\n",
    "            if not os.path.exists(f\"{folder_path}/{name}_{t}_{signer}.png\"):\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = preprocess_frame(cur_frame)\n",
    "                frame = frame.numpy()\n",
    "                #frames.append(cur_frame)\n",
    "                cv2.imwrite(f\"{folder_path}/{name}_{t}_{signer}.png\", frame)\n",
    "            t += 1\n",
    "        #fin_frames = stack_images(frames)\n",
    "        #print(len(fin_frames))\n",
    "        #for fram in fin_frames:\n",
    "        #    name = video_path.split(\"_\")[9]\n",
    "        #    cv2.imwrite(f\"{folder_path}/{name}_{t}.png\", fram)\n",
    "        #    t += 1\n",
    "        cap.release()\n",
    "\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ba05d-fc08-4456-8508-4ac17eba0927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \".../KArSL/Signer_1/Train\"\n",
    "data_dir2 = \".../KArSL/Signer_2/Train\"\n",
    "data_dir3 = \".../KArSL/Signer_3/Train\"\n",
    "classes_to_preprocess = [\"0160\", \"0162\", \"0169\", \"0173\", \"0174\", \"0230\", \"0231\", \"0265\", \"0272\", \"0290\", \n",
    "                         \"0294\", \"0296\", \"0299\", \"0343\", \"0459\", \"0468\", \"0487\", \"0497\", \"0501\", \"0502\"]\n",
    "\n",
    "for clas in tqdm(os.listdir(data_dir)):\n",
    "    if clas in classes_to_preprocess:\n",
    "        for vid in os.listdir(f\"{data_dir}/{clas}\"):\n",
    "            preprocess_video(f\"{data_dir}/{clas}/{vid}\", \"1\")\n",
    "            \n",
    "for clas in tqdm(os.listdir(data_dir2)):\n",
    "    if clas in classes_to_preprocess:\n",
    "        for vid in os.listdir(f\"{data_dir}/{clas}\"):\n",
    "            preprocess_video(f\"{data_dir}/{clas}/{vid}\", \"2\")\n",
    "            \n",
    "for clas in tqdm(os.listdir(data_dir3)):\n",
    "    if clas in classes_to_preprocess:\n",
    "        for vid in os.listdir(f\"{data_dir}/{clas}\"):\n",
    "            preprocess_video(f\"{data_dir}/{clas}/{vid}\", \"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf6208-5ca3-4073-a0c2-17fe5d51c340",
   "metadata": {},
   "source": [
    "## Extract Skleleton Keypoints from Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3649ac-bb23-4d67-a882-7183ee64b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(images_dir, label, folder_name):\n",
    "    frames = []\n",
    "    mp_holistic = mp.solutions.holistic.Holistic(static_image_mode=False)\n",
    "    for img in os.listdir(f\"{images_dir}\"):\n",
    "        frame = cv2.imread(f\"{images_dir}/{img}\")\n",
    "        keypoints_file = f\".../KArSL/all Signers/{folder_name}_keypoints.csv\"\n",
    "        \n",
    "        with open(keypoints_file, mode='a', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "\n",
    "            frame = cv2.resize(frame, (224,224))\n",
    "            results = mp_holistic.process(image=frame)\n",
    "\n",
    "            keypoints = []\n",
    "            if results.left_hand_landmarks:\n",
    "                for landmarks in results.left_hand_landmarks.landmark:\n",
    "                    keypoints.extend([landmarks.x, landmarks.y])\n",
    "            if results.right_hand_landmarks:\n",
    "                for landmarks in results.right_hand_landmarks.landmark:\n",
    "                    keypoints.extend([landmarks.x, landmarks.y])\n",
    "\n",
    "            if len(keypoints) >= 42:  # Ensure at least 43 keypoints are present\n",
    "                keypoints = keypoints[:42]  # Truncate to 43 keypoints\n",
    "                keypoints_with_label = [label] + keypoints\n",
    "                csv_writer.writerow(keypoints_with_label)\n",
    "                        \n",
    "            elif keypoints:\n",
    "                keypoints_with_label = [label] + keypoints\n",
    "                csv_writer.writerow(keypoints_with_label)\n",
    "            else:\n",
    "                #print(f\"error with {label}\")\n",
    "                continue\n",
    "\n",
    "    mp_holistic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de91c6b-47a8-4b2f-8b53-eabb4de51f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images_folder in tqdm(os.listdir(\"D:/WLASL/KArSL/all Signers/Train\")):\n",
    "    preprocess_images(f\".../KArSL/all Signers/Test/{images_folder}\", images_folder, \"train\")\n",
    "for images_folder in tqdm(os.listdir(\"D:/WLASL/KArSL/all Signers/Test\")):\n",
    "    preprocess_images(f\".../KArSL/all Signers/Test/{images_folder}\", images_folder, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0112108-b057-4f0d-87c1-efddf2cba82c",
   "metadata": {},
   "source": [
    "## Call and Preprocess Skeleton Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33af55c-4aab-4d29-9e3f-a0ecb78d8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\".../KArSL/all Signers/train_keypoints.csv\", header=None)\n",
    "test_data = pd.read_csv(\".../KArSL/all Signers/test_keypoints.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd81424-0701-4607-a20e-385d5eae6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:,1:]\n",
    "y_train = train_data.iloc[:,0]\n",
    "\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eee008-f1aa-4c5a-a53a-6d92521b478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc49b8-6043-442d-954e-c817dc37b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(y_train)\n",
    "y_train = labelencoder.transform(y_train)\n",
    "y_test = labelencoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62baf73e-03e1-493a-bdd4-9735d8c49039",
   "metadata": {},
   "source": [
    "## Train on RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc15a5e-9324-42df-b103-705572f157e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [60,80,100,120,140,160,180,200,220,240,260,280], 'max_features': ['sqrt', 'log2']}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(verbose=2), param_grid)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Grid: \", best_params)\n",
    "#plot_grid_search(grid_search.cv_results_, param_grid[\"n_estimators\"], param_grid[\"max_features\"], 'n_estimators', 'max_features')\n",
    "print(\"Grid Search is Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272f957-8a3a-493d-8019-eed577784c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**best_params)\n",
    "model = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db26b27-1bf1-4829-812f-7f3b5911af0f",
   "metadata": {},
   "source": [
    "## Train on SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3687d2a-2a87-4012-bf0b-e744685ce59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(probability=True), param_grid)\n",
    "grid_search.fit(X_train,y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Grid: \", best_params)\n",
    "print(\"Grid Search is Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b6c9c-8757-429a-8aaa-31b74ab78f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = SVC(**best_params, probability=True)\n",
    "model = rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8a58c-907b-47f8-9195-d158a4a9be27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c2ade-61df-47ba-8f2c-cadf825ae0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "print(cm)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "#accuracy2 = accuracy_score(y_test2, y_pred2)\n",
    "print(\"Accuracy 1 :\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "#print(\"Accuracy 2 :\", accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5a28a-5395-4906-955d-addeefb8ae43",
   "metadata": {},
   "source": [
    "## Train on CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7371404-c7eb-4a85-a19c-50328c21b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the path to the reorganized dataset folders\n",
    "train_data_dir = 'D:/WLASL/KArSL/all Signers/Train'\n",
    "test_data_dir = 'D:/WLASL/KArSL/all Signers/Test'\n",
    "#test2_data_dir = 'D:/WLASL/KArSL/Signer_2/all_image_test'\n",
    "# Create an ImageDataGenerator instance with appropriate data augmentation settings\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalize pixel values\n",
    "    validation_split=0.20,\n",
    "    #rotation_range=0.2,  # Example augmentation settings, modify as needed\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    #horizontal_flip=True,\n",
    "    #brightness_range=[0.2,1.0]\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0  # Normalize pixel values\n",
    ")\n",
    "# Prepare the training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    seed=42,\n",
    "    subset = \"training\"\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    seed=42,\n",
    "    subset = \"validation\"\n",
    ")\n",
    "\n",
    "\n",
    "# Prepare the testing data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1b415-ac38-474c-86f4-d5ea90ab5c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model = tf.keras.models.Sequential([\n",
    "    #data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224,224,3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True, dropout=0.7),\n",
    "    tf.keras.layers.LSTM(32, dropout=0.7),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(20, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=[\"accuracy\",\n",
    "                      tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.AUC(name='AUC')])\n",
    "\n",
    "model.fit(train_generator, epochs=200, batch_size=64\n",
    "          , validation_data=val_generator, callbacks=[early_stopping, tensorboard_callback])\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aefa999-4ee0-439a-8fb2-f4c256c00fbe",
   "metadata": {},
   "source": [
    "## Train on CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc30bcd-7338-4c29-b397-69952a42df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model = tf.keras.models.Sequential([\n",
    "    #data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224,224,3)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(20, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "              metrics=[\"accuracy\",\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall'),\n",
    "                       tf.keras.metrics.AUC(name='AUC')])\n",
    "\n",
    "model.fit(train_generator, epochs=200, batch_size=128\n",
    "          , validation_data=val_generator, callbacks=[early_stopping, tensorboard_callback])\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b38d5-3557-411a-92ae-5529cf243b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19805125-f154-45b4-bbc0-3e5587bcf384",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Convert predictions and true labels to arrays\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c217a52-ed06-4ad0-a2ad-aead5ef6b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/WLASL/KArSL/model_5_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d205ce9-a896-4b39-bd2d-adbf07774436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.load_model('D:/WLASL/KArSL/model_5_cnnlstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8a86f-ed98-4b9d-ac0e-89c9f64a4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_1)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model\n",
    "with open('D:/WLASL/KArSL/model_5_cnnlstm.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327eef8d-6b70-4d42-b327-46a7ae7adce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
